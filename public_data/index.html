<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="canonical" href="https://webmev.tm4.org/public_data/">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Creating and managing public data - WebMeV REST API</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  <link href="../style.css" rel="stylesheet" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Creating and managing public data";
    var mkdocs_page_input_path = "public_data.md";
    var mkdocs_page_url = "/public_data/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> WebMeV REST API</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../general_architecture/">Architecture</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Installation and Setup</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../install/">Preliminaries</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../mev_cluster_setup/">Installation and setup</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../setup_configuration/">Configuration</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../management_commands/">Management commands</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../data_server/">Mock data server</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">API</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../api/">Intro and core concepts</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Data Structures</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="#">Resources</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../resources/">General info</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../resource_types/">Resource types</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../resource_metadata/">Resource metadata</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../operation_resources/">Operation-associated resources</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../attributes/">Attributes</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../elements/">Observations and Features</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../observation_and_feature_sets/">ObservationSet and FeatureSets</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../workspaces/">Workspaces</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../metadata/">Workspace metadata</a>
                </li>
    </ul>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../auth/">Authentication</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../operations/">Operation concepts</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../creating_analyses/">Creating new analyses/operations</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../example_workflow/">Workflow and analysis concepts</a>
                    </li>
                </ul>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Creating and managing public data</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#step-1-defining-and-creating-the-data">Step 1: Defining and creating the data</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#step-2-define-and-create-the-solr-core">Step 2: Define and create the solr core</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#step-3-obtaining-and-modifying-the-data-schema">Step 3: Obtaining and modifying the data schema</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#step-4-copy-the-core-files-to-the-repository-and-commit">Step 4: Copy the core files to the repository and commit</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#step-5-verify">Step 5: Verify</a>
    </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">WebMeV REST API</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Creating and managing public data</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/web-mev/mev-backend/edit/master/docs/public_data.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h3 id="working-with-public-datasets"><a class="toclink" href="#working-with-public-datasets">Working with public datasets</a></h3>
<p>WebMeV provides the ability to easily create custom datasets derived from publicly available databases such as the Cancer Genome Atlas (TCGA). Query functionality of these datasets is exposed through Solr, which provides us a standard indexing and query syntax.</p>
<p>Given that each data repository has different formats and content, this functionality requires some custom code to create and manage the data on a case-by-case basis. In this guide, we describe the necessary elements to create/index a new data source.</p>
<p>In this guide, we will often refer to the TCGA RNA-seq as a prototypical example. This dataset contains count-based RNA-seq data downloaded from the NCI's genomic data commons (GDC) repository under the TCGA project.</p>
<h4 id="step-1-defining-and-creating-the-data"><a class="toclink" href="#step-1-defining-and-creating-the-data">Step 1: Defining and creating the data</a></h4>
<p>To create a new public dataset, we need to define how the data is collected and prepared. This section describes how to write the proper hooks for data ingestion and preparation.</p>
<p><strong>1.1 Create a new directory for your dataset</strong></p>
<p>To keep everything organized, we expect that each dataset will be kept in separate subdirectories of the <code>mev/api/public_data/sources</code> directory. However, note that there is no enforcement of this convention or any expected hierarchy of those subdirectories.</p>
<p><em>Example:</em>
Note that <code>mev/api/public_data/sources</code> contains a <code>gdc</code> subdirectory and was created with the intent of holding all GDC projects; beyond TCGA, there are many other datasets exposed via the GDC repository. We expect that more of these GDC datasets will be included over time, so this was a logical way to structure the folder. You may choose to structure new datasets in an alternate manner.</p>
<p>The <code>gdc</code> directory contains several python modules which define how the GDC-derived datasets are to be downloaded and prepared. We define a <code>gdc.py</code> module which contains code expected to be common to all GDC projects. Code specific to preparation of TCGA data is contained in the <code>tcga.py</code> module. </p>
<p><strong>1.2 Create an implementing class</strong></p>
<p>To provide a common means of ingesting/preparing all datasets, we expect that each dataset will be mapped 1:1 with a Python class that derives from <code>api.public_data.sources.base.PublicDataset</code>. This class requires the following:</p>
<ul>
<li>Class attributes:<ul>
<li><code>TAG</code>: This is a unique string which acts as an identifier for the dataset. If the name is not unique, then registering the dataset in the database will not be permitted, and hence the indexed dataset will not be usable. Additionally, the unit test suite will check that all implementing classes have unique identifiers. This string is limited to 30 characters by a database constraint.</li>
<li><code>PUBLIC_NAME</code>: This string should be a relatively short "name" for the dataset, such as "TCGA RNA-seq"</li>
<li><code>DESCRIPTION</code>: This is another string which provides more context and a thorough description of the data is contains.</li>
</ul>
</li>
<li>Methods:<ul>
<li><code>prepare(self)</code>: a method that takes no arguments (other than the class instance) and prepares the data. A return value is not expected.</li>
</ul>
</li>
</ul>
<p>A template for this new class:</p>
<pre class="codehilite"><code>from api.public_data.sources.base import PublicDataset

class MyDataset(PublicDataset):

    TAG = ''
    PUBLIC_NAME = ''
    DESCRIPTION = ''

    def prepare(self):
        pass
</code></pre>

<p>Note that you are not obligated to derive your implementation directly from <code>PublicDataset</code>; for the TCGA RNA-seq example, we created a hierarchy of <code>PublicDataset</code>-&gt; <code>GDCDataSource</code> -&gt; <code>TCGADataSource</code> -&gt; <code>TCGARnaSeqDataSource</code> which reflects the fact that certain functionality is general to all GDC data sources and hence can be re-used if we incorporate other datasets from the GDC.</p>
<p>Also note that we make no requirements for the <code>prepare</code> method. In its simplest implementation, the dataset can be manually prepared and the <code>prepare</code> method can be left as an empty pass-through. This is the easiest option for datasets that are not actively updated or are difficult to automate. However, <em>you still need to define this implementing class, even if the implementation is trivial</em>.</p>
<p>More generally, the <code>prepare</code> method is the entry function for potentially many steps of data download and preparation. Again, while not enforced, we expect that the prepared data will ultimately be located under the <code>/data/public_data</code> directory so that it will be consistent with other data sources and can be persisted on redeployments. </p>
<p><strong>1.3 "Register" the implementing class</strong></p>
<p>To allow WebMeV to "see" this new implementation, we have to add it to the <code>IMPLEMENTING_CLASSES</code> list in <code>api/public_data/__init__.py</code>. If this is not done, you will receive errors that will warn you of an unknown dataset.</p>
<h4 id="step-2-define-and-create-the-solr-core"><a class="toclink" href="#step-2-define-and-create-the-solr-core">Step 2: Define and create the solr core</a></h4>
<p>Instead of dynamically creating Solr cores during machine provisioning, we instead create all the necessary files up front so that they are included with the WebMeV repository. This consists of two steps:</p>
<ul>
<li>create a basic core config</li>
<li>replace the auto-generated schema with a dataset-specific schema.xml</li>
</ul>
<p><strong>2.1 Creating the core (temporary workaround)</strong></p>
<p>Due to various interactions of the <code>root</code>, <code>solr</code>, and system user (<code>vagrant</code>), you need to use the following steps to create the proper files for a new solr core. The steps below were performed on a local Vagrant-based machine.</p>
<p><strong>Important: the name of the Solr core you create MUST match the <code>TAG</code> attribute of your implementing class</strong>. This is how the implementing class knows which Solr core to query.</p>
<ul>
<li>
<p>Open <code>/etc/default/solr</code> and edit <code>SOLR_HOME=/var/solr/data</code></p>
</li>
<li>
<p>Restart the solr service with <code>sudo systemctl restart solr</code></p>
</li>
<li>
<p>Create the core: <code>sudo -u solr /opt/solr/bin/solr create_core -c &lt;core name&gt;</code></p>
</li>
</ul>
<h4 id="step-3-obtaining-and-modifying-the-data-schema"><a class="toclink" href="#step-3-obtaining-and-modifying-the-data-schema">Step 3: Obtaining and modifying the data schema</a></h4>
<p><strong>3.1 Index an example file</strong></p>
<p>Above, Solr will create a default/schemaless core to index general data. For our purposes, the data is more structured and we typically have some notion of data structures and types in a given dataset. Furthermore, we don't want to necessarily rely on Solr to properly guess the types of various fields.</p>
<p>Hence, we will first use Solr to auto-index an example file. Following this, we will request a "dump" of the current schema which we will subsequently edit to fit our needs. Ideally, the example file you use below is very close to the final data you are hoping to index (or <em>is</em> the data you want to expose). </p>
<p>To index the example file:</p>
<pre class="codehilite"><code>/opt/solr/bin/solr post -c &lt;core name&gt; &lt;file path&gt;
</code></pre>

<p><strong>3.2 Query for the current schema and edit</strong>
Now, we will query for the current/inferred schema. Here, we put this in the <code>/vagrant/solr</code> directory, but it does not really matter where it goes, as long as you remember.</p>
<pre class="codehilite"><code>curl http://localhost:8983/solr/&lt;core name&gt;/schema?wt=schema.xml &gt;/vagrant/solr/current_schema.xml
</code></pre>

<p>This <code>curl</code> request will provide the structured XML schema that is currently supporting the core.</p>
<p>At the top of the <code>current_schema.xml</code> file you will see many field type (<code>&lt;fieldType&gt;</code>) entries, which can be left as-is. You may, however, wish to remove those that are (likely) unnecessary. Examples include various tokenizer classes and filters corresponding to free-text analyzers and considerations for foreign language support. Those fields are not likely to be too relevant for most biomedical data we are analyzing within WebMeV. However, it is fine to leave those all.</p>
<p>You <strong>will</strong>, however, want to make edits to the <code>&lt;field&gt;</code> entities located towards the tail of the schema. You should see field names corresponding to the columns/fields of the example file you indexed before. Depending on your data, you may choose to edit the <code>type</code> attributes. For instance, the default may be something like:</p>
<pre class="codehilite"><code>&lt;field name=&quot;year_of_birth&quot; type=&quot;pdoubles&quot;/&gt;
</code></pre>

<p>but we may wish to change that to integers:</p>
<pre class="codehilite"><code>&lt;field name=&quot;year_of_birth&quot; type=&quot;pint&quot;/&gt;
</code></pre>

<p>Similarly, many string-based fields are given a type of <code>text_general</code> which causes solr to initiate various NLP methods on these fields. In most cases of biomedical data, these fields can better be indexed using a <code>string</code> type, which avoids unnecessary text processing. Instead, the values in <code>string</code> types are treated like enumerables instead of a free text field that requires analysis. For example, in the TCGA dataset, we have a finite number of defined cancer types (e.g. TCGA-BRCA) that appear in the <code>project_id</code> field, thus, we can edit:</p>
<pre class="codehilite"><code>&lt;field name=&quot;project_id&quot; type=&quot;text_general&quot;/&gt;
</code></pre>

<p>to </p>
<pre class="codehilite"><code>&lt;field name=&quot;project_id&quot; type=&quot;string&quot;/&gt;
</code></pre>

<p>Similarly, there will likely be many <code>&lt;dynamicField&gt;</code> entries which can be removed.</p>
<p>In the end, you should be able to have a simple, human-interpretable list of fields that correspond to data types you recognize in the dataset. You <em>could</em> have created this all yourself, but Solr typically does a good job of guessing for most things.</p>
<h4 id="step-4-copy-the-core-files-to-the-repository-and-commit"><a class="toclink" href="#step-4-copy-the-core-files-to-the-repository-and-commit">Step 4: Copy the core files to the repository and commit</a></h4>
<p>Recall that to create your core, we had to do a bit of a workaround above. The files defining your solr core are located in <code>/var/solr/data/&lt;core name&gt;</code>. We want to copy these files and our edited schema (AND remove the managed schema) to the WebMeV repository so that all the required items will be there for the new dataset. Hence:</p>
<pre class="codehilite"><code>cd /vagrant/solr
mkdir &lt;core name&gt;
sudo cp /var/solr/data/blah/core.properties &lt;core name&gt;/
sudo cp -r /var/solr/data/blah/conf &lt;core name&gt;/
rm &lt;core name&gt;/conf/managed-schema
cp /vagrant/solr/current_schema.xml &lt;core name&gt;/conf/schema.xml
</code></pre>

<p>At this point, the core files should be ready. You can commit these files to the repository.</p>
<h4 id="step-5-verify"><a class="toclink" href="#step-5-verify">Step 5: Verify</a></h4>
<p>To be sure that everything works, it's best to start a fresh local build. Since we manually created a new core and modified some of Solr's configuration files, we need to ensure our new dataset files work out of the box.</p>
<p>Destroy and re-created the VM however you wish. After, you can attempt to index a file into your new collection using the management commands we provide.</p>
<p>If you want to test the data download/preparation process, SSH into your VM and run</p>
<pre class="codehilite"><code>python3 manage.py pull_public_data -d &lt;core name&gt;
</code></pre>

<p>Then, to index a file into this core:</p>
<pre class="codehilite"><code>python3 manage.py index_data -d &lt;core name&gt; &lt;path&gt; [&lt;path&gt; ...]
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../example_workflow/" class="btn btn-neutral" title="Workflow and analysis concepts"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/web-mev/mev-backend/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../example_workflow/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
