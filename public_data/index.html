<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://webmev.tm4.org/public_data/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Creating and managing public data - WebMeV REST API</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Creating and managing public data";
        var mkdocs_page_input_path = "public_data.md";
        var mkdocs_page_url = "/public_data/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> WebMeV REST API
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../general_architecture/">Architecture</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Installation and Setup</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../install/">Install</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../setup_configuration/">Configuration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../management_commands/">Management commands</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">API</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../api/">Intro and core concepts</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Data Structures</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="#">Resources</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../resources/">General info</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../resource_types/">Resource types</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../resource_metadata/">Resource metadata</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../operation_resources/">Operation-associated resources</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../attributes/">Attributes</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../elements/">Observations and Features</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../observation_and_feature_sets/">ObservationSet and FeatureSets</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../workspaces/">Workspaces</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../metadata/">Workspace metadata</a>
                </li>
    </ul>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../auth/">Authentication</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../operations/">Operation concepts</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../creating_analyses/">Creating new analyses/operations</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../example_workflow/">Workflow and analysis concepts</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Creating and managing public data</a>
    <ul class="current">
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">WebMeV REST API</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Creating and managing public data</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/web-mev/mev-backend/edit/master/docs/public_data.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h3 id="working-with-public-datasets"><a class="toclink" href="#working-with-public-datasets">Working with public datasets</a></h3>
<p>WebMeV provides the ability to easily create custom datasets derived from publicly available databases such as the Cancer Genome Atlas (TCGA). Query functionality of these datasets is exposed through Solr, which provides us a standard indexing and query syntax.</p>
<p>Given that each data repository has different formats and content, this functionality requires some custom code to create and manage the data on a case-by-case basis. In this guide, we describe the necessary elements to create/index a new data source.</p>
<p>In this guide, we will often refer to the TCGA RNA-seq as a prototypical example. This dataset contains count-based RNA-seq data downloaded from the NCI's genomic data commons (GDC) repository under the TCGA project.</p>
<h3 id="the-quick-way"><a class="toclink" href="#the-quick-way">The quick way:</a></h3>
<p>For convenience, there is a management command that handles most of the steps. Be sure to pay attention to the log messages, as they will direct you to change various things. If that script fails for whatever reason, we provide all the atomic details below.</p>
<p>Run the following in your Vagrant build:</p>
<pre class="codehilite"><code>python3 manage.py create_new_public_dataset \
    -d &lt;core name&gt;
    -f &lt;path to an example file you want to index&gt;
</code></pre>

<p>The core name (<code>-d</code>) should be relatively short/simple (e.g. <code>ccle-data</code>) and the the file (<code>-f</code>) should be an example of the data you wish to index. It can be a row subset (not ALL the data), but should have all the potential fields.</p>
<p>Note that the script will still require you to fill out the stubbed-out python module for the new dataset AND also require you to add some content to the Puppet manifests to fully integrate this new core. The script will direct you to the stubs and remind you what needs to be done.</p>
<p>You will also need to commit the solr files (<code>solr/&lt;core&gt;/schema.xml</code>  and <code>solr/&lt;core&gt;/solrconfig.xml</code>) when everything is fully ready.</p>
<hr />
<h3 id="the-longer-way-or-the-way-if-the-script-above-does-not-work"><a class="toclink" href="#the-longer-way-or-the-way-if-the-script-above-does-not-work">The longer way (or the way if the script above does not work!)</a></h3>
<h4 id="step-1-defining-and-creating-the-data"><a class="toclink" href="#step-1-defining-and-creating-the-data">Step 1: Defining and creating the data</a></h4>
<p>To create a new public dataset, we need to define how the data is collected and prepared. This section describes how to write the proper hooks for data ingestion and preparation.</p>
<p><strong>1.1 Create a new directory for your dataset</strong></p>
<p>To keep everything organized, we expect that each dataset will be kept in separate subdirectories of the <code>mev/api/public_data/sources</code> directory. However, note that there is no enforcement of this convention or any expected hierarchy of those subdirectories.</p>
<p><em>Example:</em>
Note that <code>mev/api/public_data/sources</code> contains a <code>gdc</code> subdirectory and was created with the intent of holding all GDC projects; beyond TCGA, there are many other datasets exposed via the GDC repository. We expect that more of these GDC datasets will be included over time, so this was a logical way to structure the folder. You may choose to structure new datasets in an alternate manner.</p>
<p>The <code>gdc</code> directory contains several python modules which define how the GDC-derived datasets are to be downloaded and prepared. We define a <code>gdc.py</code> module which contains code expected to be common to all GDC projects. Code specific to preparation of TCGA data is contained in the <code>tcga.py</code> module. </p>
<p><strong>1.2 Create an implementing class</strong></p>
<p>To provide a common means of ingesting/preparing all datasets, we expect that each dataset will be mapped 1:1 with a Python class that derives from <code>api.public_data.sources.base.PublicDataset</code>. This class requires the following:</p>
<ul>
<li>Class attributes:<ul>
<li><code>TAG</code>: This is a unique string which acts as an identifier for the dataset. If the name is not unique, then registering the dataset in the database will not be permitted, and hence the indexed dataset will not be usable. Additionally, the unit test suite will check that all implementing classes have unique identifiers. This string is limited to 30 characters by a database constraint.</li>
<li><code>PUBLIC_NAME</code>: This string should be a relatively short "name" for the dataset, such as "TCGA RNA-seq"</li>
<li><code>DESCRIPTION</code>: This is another string which provides more context and a thorough description of the data is contains.</li>
<li><code>DATASET_FILES</code>: This is a list which enumerates the files necessary for this dataset. For example, in the TCGA RNA-seq dataset, we have the metadata/annotations file, and we have a separate count file. This list of used to ensure that the proper
files are present when indexing and creating datasets.</li>
</ul>
</li>
<li>Methods:<ul>
<li><code>prepare(self)</code>: a method that takes no arguments (other than the class instance) and prepares the data. A return value is not expected.</li>
<li><code>verify_files(self, file_dict)</code>: a method that takes a dictionary with keys that should match those in <code>DATASET_FILES</code> and the values are file paths so we can verify
that the files exist.</li>
<li><code>get_indexable_files(self, file_dict)</code>: a method that iterates through the passed
dictionary and returns a list of file paths for files that are to be indexed.</li>
<li><code>get_additional_metadata(self)</code>: a method that returns a dictionary containing additional information that is relevant to the dataset, but not part of the traditional data or metadata. An example from the TCGA project is a mapping of the TCGA IDs (e.g. "TCGA-LUAD") to full names (e.g. "Lung adenocarcinoma"). The results of this method are placed into the <code>additional_metadata</code> JSON field in the database. There is no defined structure so that each dataset will be different in general.</li>
<li><code>create_from_query(self, query_params)</code>: a method that takes a dict which specifies how to create the dataset. Think of the dict as a generic payload
for filtering, etc. Returns a tuple of a filepath(string) and a resource type string (one of our "special" types like <code>"EXP_MTX"</code>)</li>
</ul>
</li>
</ul>
<p>A template for this new class:</p>
<pre class="codehilite"><code>from api.public_data.sources.base import PublicDataSource

class MyDataset(PublicDataSource):

    TAG = ''
    PUBLIC_NAME = ''
    DESCRIPTION = ''
    DATASET_FILES = []
    def prepare(self):
        pass
    def verify_files(self, file_dict):
        pass
    def get_indexable_files(self, file_dict):
        pass
    def create_from_query(self, query_params):
        pass
</code></pre>

<p>Note that you are not obligated to derive your implementation directly from <code>PublicDataset</code>; for the TCGA RNA-seq example, we created a hierarchy of <code>PublicDataset</code>-&gt; <code>GDCDataSource</code> -&gt; <code>TCGADataSource</code> -&gt; <code>TCGARnaSeqDataSource</code> which reflects the fact that certain functionality is general to all GDC data sources and hence can be re-used if we incorporate other datasets from the GDC.</p>
<p>Also note that we make no requirements for the <code>prepare</code> method. In its simplest implementation, the dataset can be manually prepared and the <code>prepare</code> method can be left as an empty pass-through. This is the easiest option for datasets that are not actively updated or are difficult to automate. However, <em>you still need to define this implementing class, even if the implementation is trivial</em>.</p>
<p>More generally, the <code>prepare</code> method is the entry function for potentially many steps of data download and preparation. Again, while not enforced, we expect that the prepared data will ultimately be located under the <code>/data/public_data</code> directory so that it will be consistent with other data sources and can be persisted on redeployments. </p>
<p><strong>1.3 "Register" the implementing class</strong></p>
<p>To allow WebMeV to "see" this new implementation, we have to add it to the <code>IMPLEMENTING_CLASSES</code> list in <code>api/public_data/__init__.py</code>. If this is not done, you will receive errors that will warn you of an unknown dataset.</p>
<h4 id="step-2-define-your-solr-core"><a class="toclink" href="#step-2-define-your-solr-core">Step 2: Define your solr core</a></h4>
<p>The process of adding new cores for additional datasets is handled during provisioning and requires changes to the Puppet scripts. However, prior to that point, we need to create the proper files that will be used to create this new core. This section covers details of how to create these files.</p>
<p>To do this, below we will perform the following:</p>
<ul>
<li>Create a new (but ephemeral) Solr core</li>
<li>Index an example file from your dataset using Solr's auto-detection functionality</li>
<li>Query the auto-generated schema and edit it to ensure the inferred field types are correct. </li>
</ul>
<p>After these steps, we will have the necessary files which we can add to the WebMeV repository.  The provisioning process will then use those files to add the new core.</p>
<p><strong>2.1 Creating the core</strong></p>
<p>This step assumes you have a Vagrant-based system up and have SSH'd in. By default, you are the <code>vagrant</code> user.</p>
<p><strong>Important: the name of the Solr core you create MUST match the <code>TAG</code> attribute of your implementing class</strong>. This is how the implementing class knows which Solr core to query.</p>
<p>Run:</p>
<p><code>sudo -u solr /opt/solr/bin/solr create_core -c &lt;core name&gt;</code></p>
<p>Solr should report that the new core was created.</p>
<h4 id="step-3-obtaining-and-modifying-the-data-schema"><a class="toclink" href="#step-3-obtaining-and-modifying-the-data-schema">Step 3: Obtaining and modifying the data schema</a></h4>
<p><strong>3.1 Index an example file</strong></p>
<p>Above, Solr will create a default/schemaless core. For our purposes in WebMeV, the data is typically more structured and we have some notion of data structures and types in a given dataset (e.g. age as an integer type). Furthermore, we don't want to necessarily rely on Solr to properly guess the types of various fields.</p>
<p>Hence, we will first use Solr to auto-index an example file. Following this, we will request a "dump" of the current schema which we will subsequently edit to fit our needs. Ideally, the example file you use below is very close to the final data you are hoping to index (or <em>is</em> the data you want to expose). Mismatches between the schema and the data files will cause failures. </p>
<p>To index the example file:</p>
<pre class="codehilite"><code>/opt/solr/bin/post -c &lt;core name&gt; &lt;file path&gt;
</code></pre>

<p><strong>3.2 Query for the current schema and edit</strong>
Now, we will query for the current/inferred schema that was just created. Here, we put this in the <code>/vagrant/solr</code> directory, but it does not really matter where it goes, as long as you remember.</p>
<pre class="codehilite"><code>curl http://localhost:8983/solr/&lt;core name&gt;/schema?wt=schema.xml &gt;/vagrant/solr/current_schema.xml
</code></pre>

<p>This <code>curl</code> request will provide the structured XML schema that is currently supporting the core.</p>
<p>At the top of the <code>current_schema.xml</code> file you will see many field type (<code>&lt;fieldType&gt;</code>) entries, which can be left as-is. You may, however, wish to remove those that are (likely) unnecessary. Examples include various tokenizer classes and filters corresponding to free-text analyzers and considerations for foreign language support. Those fields are not likely to be too relevant for most biomedical data we are analyzing within WebMeV. However, it is also fine to leave those all as-is.</p>
<p>You <strong>will</strong>, however, want to review and potentially make edits to the <code>&lt;field&gt;</code> entities located towards the tail of the schema. You should see field names corresponding to the columns/fields of the example file you indexed before. Depending on your data, you may choose to edit the <code>type</code> attributes. For instance, the default may be something like:</p>
<pre class="codehilite"><code>&lt;field name=&quot;year_of_birth&quot; type=&quot;pdoubles&quot;/&gt;
</code></pre>

<p>but we may wish to change that to integers:</p>
<pre class="codehilite"><code>&lt;field name=&quot;year_of_birth&quot; type=&quot;pint&quot;/&gt;
</code></pre>

<p>Similarly, many string-based fields default to a type of <code>text_general</code> which causes solr to initiate various NLP methods on these fields upon query. In most cases of biomedical data, these fields can better be indexed using a <code>string</code> type, which avoids unnecessary text processing. Values in <code>string</code> types are treated like enumerables (i.e. a finite set of strings) instead of a free text field that requires analysis. For example, in the TCGA dataset, we have a finite number of defined cancer types (e.g. TCGA-BRCA) that appear in the <code>project_id</code> field, thus, we can edit:</p>
<pre class="codehilite"><code>&lt;field name=&quot;project_id&quot; type=&quot;text_general&quot;/&gt;
</code></pre>

<p>to </p>
<pre class="codehilite"><code>&lt;field name=&quot;project_id&quot; type=&quot;string&quot;/&gt;
</code></pre>

<p><strong>Important:</strong> Do NOT remove this field, as this causes a failure to build the core on provisioning:</p>
<pre class="codehilite"><code>&lt;field name=&quot;_version_&quot; type=&quot;plong&quot; indexed=&quot;false&quot; stored=&quot;false&quot;/&gt;
</code></pre>

<p>There will likely be many <code>&lt;dynamicField&gt;</code> and <code>&lt;copyField&gt;</code> entries which can be removed. These are added to enable further text processing that (usually) is not necessary and only increases the size of the index.</p>
<p>In the end, you should have a simple, human-interpretable list of fields that correspond to data types you recognize in the dataset. You <em>could</em> have created this all yourself, but Solr typically does a good job of guessing for most things.</p>
<h4 id="step-4-copy-the-core-files-to-the-repository-and-commit"><a class="toclink" href="#step-4-copy-the-core-files-to-the-repository-and-commit">Step 4: Copy the core files to the repository and commit</a></h4>
<p>Recall that to create your core, we had to do a bit of a workaround above. The files defining your solr core are located in <code>/var/solr/data/&lt;core name&gt;</code>. We want to copy these files and our edited schema (AND remove the managed schema) to the WebMeV repository so that all the required items will be there for the new dataset. Hence:</p>
<pre class="codehilite"><code>cd /vagrant/solr
mkdir &lt;core name&gt;
cp /vagrant/solr/edited_schema.xml &lt;core name&gt;/schema.xml
cp /vagrant/solr/basic_solrconfig.xml &lt;core name&gt;/solrconfig.xml
</code></pre>

<p>At this point, the core files should be ready. You can commit these files to the repository.</p>
<h4 id="step-5-add-the-core-to-your-puppet-manifest"><a class="toclink" href="#step-5-add-the-core-to-your-puppet-manifest">Step 5: Add the core to your Puppet manifest</a></h4>
<p>By adding the following snippet to your Puppet manifest at <code>deploy/puppet/mevapi/manifests/init.pp</code>, the provisioning step will create the necessary elements so that
your new core will be ready-to-go on the next round of provisioning:</p>
<p>Replace <code>&lt;CORE&gt;</code> below:</p>
<pre class="codehilite"><code>  solr::core { '&lt;CORE&gt;':
    schema_src_file     =&gt; &quot;${project_root}/solr/&lt;CORE&gt;/schema.xml&quot;,
    solrconfig_src_file =&gt; &quot;${project_root}/solr/&lt;CORE&gt;/solrconfig.xml&quot;,
  }
</code></pre>

<h4 id="step-6-verify"><a class="toclink" href="#step-6-verify">Step 6: Verify</a></h4>
<p>To be sure that everything works, it's best to start a fresh local build. Since we manually created a new core and modified some of Solr's configuration files, we need to ensure our new dataset files work out of the box.</p>
<p>Destroy and re-created the VM however you wish. After, you can attempt to index a file into your new collection using the management commands we provide.</p>
<p>If you want to test the data download/preparation process, SSH into your VM and run</p>
<pre class="codehilite"><code>python3 manage.py pull_public_data -d &lt;core name&gt;
</code></pre>

<p>Then, to index a file into this core:</p>
<pre class="codehilite"><code>python3 manage.py index_data -d &lt;core name&gt; &lt;path&gt; [&lt;path&gt; ...]
</code></pre>

<p>Finally, note that if you core expected core does not exist, you can always check by visiting the Solr admin interface at http://localhost:8983/solr/ on the host machine. The "core admin" tab will typically report error messages that occurred.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../example_workflow/" class="btn btn-neutral float-left" title="Workflow and analysis concepts"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/web-mev/mev-backend" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../example_workflow/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
